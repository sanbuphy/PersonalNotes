{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用PaddleNLP语义预训练模型ERNIE完成快递单信息抽取\n",
    "\n",
    "命名实体识别是NLP中一项非常基础的任务，是信息提取、问答系统、句法分析、机器翻译等众多NLP任务的重要基础工具。命名实体识别的准确度，决定了下游任务的效果，是NLP中的一个基础问题。在NER任务提供了两种解决方案，一类LSTM/GRU + CRF，通过RNN类的模型来抽取底层文本的信息，而CRF(条件随机场)模型来学习底层Token之间的联系；另外一类是通过预训练模型，例如ERNIE，BERT模型，直接来预测Token的标签信息。\n",
    "\n",
    "本项目将演示如何使用PaddleNLP语义预训练模型ERNIE完成从快递单中抽取姓名、电话、省、市、区、详细地址等内容，形成结构化信息。辅助物流行业从业者进行有效信息的提取，从而降低客户填单的成本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在2017年之前，工业界和学术界对文本处理依赖于序列模型[Recurrent Neural Network (RNN)](https://baike.baidu.com/item/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/23199490?fromtitle=RNN&fromid=5707183&fr=aladdin).\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"http://colah.github.io/posts/2015-09-NN-Types-FP/img/RNN-general.png\" width=\"40%\" height=\"30%\"> <br />\n",
    "</p><br><center>图1：RNN示意图</center></br>\n",
    "\n",
    "[基于BiGRU+CRF的快递单信息抽取](https://aistudio.baidu.com/aistudio/projectdetail/1317771)项目介绍了如何使用序列模型完成快递单信息抽取任务。\n",
    "<br>\n",
    "\n",
    "近年来随着深度学习的发展，模型参数的数量飞速增长。为了训练这些参数，需要更大的数据集来避免过拟合。然而，对于大部分NLP任务来说，构建大规模的标注数据集非常困难（成本过高），特别是对于句法和语义相关的任务。相比之下，大规模的未标注语料库的构建则相对容易。为了利用这些数据，我们可以先从其中学习到一个好的表示，再将这些表示应用到其他任务中。最近的研究表明，基于大规模未标注语料库的预训练模型（Pretrained Models, PTM) 在NLP任务上取得了很好的表现。\n",
    "\n",
    "近年来，大量的研究表明基于大型语料库的预训练模型（Pretrained Models, PTM）可以学习通用的语言表示，有利于下游NLP任务，同时能够避免从零开始训练模型。随着计算能力的不断提高，深度模型的出现（即 Transformer）和训练技巧的增强使得 PTM 不断发展，由浅变深。\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/327f44ff3ed24493adca5ddc4dc24bf61eebe67c84a6492f872406f464fde91e\" width=\"60%\" height=\"50%\"> <br />\n",
    "</p><br><center>图2：预训练模型一览，图片来源于：https://github.com/thunlp/PLMpapers</center></br>\n",
    "                                                                                                                             \n",
    "本示例展示了以ERNIE([Enhanced Representation through Knowledge Integration](https://arxiv.org/pdf/1904.09223))为代表的预训练模型如何Finetune完成序列标注任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_a\tlabel\n",
      "黑\u0002龙\u0002江\u0002省\u0002双\u0002鸭\u0002山\u0002市\u0002尖\u0002山\u0002区\u0002八\u0002马\u0002路\u0002与\u0002东\u0002平\u0002行\u0002路\u0002交\u0002叉\u0002口\u0002北\u00024\u00020\u0002米\u0002韦\u0002业\u0002涛\u00021\u00028\u00026\u00020\u00020\u00020\u00020\u00029\u00021\u00027\u00022\tA1-B\u0002A1-I\u0002A1-I\u0002A1-I\u0002A2-B\u0002A2-I\u0002A2-I\u0002A2-I\u0002A3-B\u0002A3-I\u0002A3-I\u0002A4-B\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002P-B\u0002P-I\u0002P-I\u0002T-B\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\n",
      "广\u0002西\u0002壮\u0002族\u0002自\u0002治\u0002区\u0002桂\u0002林\u0002市\u0002雁\u0002山\u0002区\u0002雁\u0002山\u0002镇\u0002西\u0002龙\u0002村\u0002老\u0002年\u0002活\u0002动\u0002中\u0002心\u00021\u00027\u00026\u00021\u00020\u00023\u00024\u00028\u00028\u00028\u00028\u0002羊\u0002卓\u0002卫\tA1-B\u0002A1-I\u0002A1-I\u0002A1-I\u0002A1-I\u0002A1-I\u0002A1-I\u0002A2-B\u0002A2-I\u0002A2-I\u0002A3-B\u0002A3-I\u0002A3-I\u0002A4-B\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002T-B\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002P-B\u0002P-I\u0002P-I\n",
      "1\u00025\u00026\u00025\u00022\u00028\u00026\u00024\u00025\u00026\u00021\u0002河\u0002南\u0002省\u0002开\u0002封\u0002市\u0002顺\u0002河\u0002回\u0002族\u0002区\u0002顺\u0002河\u0002区\u0002公\u0002园\u0002路\u00023\u00022\u0002号\u0002赵\u0002本\u0002山\tT-B\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002A1-B\u0002A1-I\u0002A1-I\u0002A2-B\u0002A2-I\u0002A2-I\u0002A3-B\u0002A3-I\u0002A3-I\u0002A3-I\u0002A3-I\u0002A4-B\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002P-B\u0002P-I\u0002P-I\n",
      "河\u0002北\u0002省\u0002唐\u0002山\u0002市\u0002玉\u0002田\u0002县\u0002无\u0002终\u0002大\u0002街\u00021\u00025\u00029\u0002号\u00021\u00028\u00026\u00021\u00024\u00022\u00025\u00023\u00020\u00025\u00028\u0002尚\u0002汉\u0002生\tA1-B\u0002A1-I\u0002A1-I\u0002A2-B\u0002A2-I\u0002A2-I\u0002A3-B\u0002A3-I\u0002A3-I\u0002A4-B\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002A4-I\u0002T-B\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002T-I\u0002P-B\u0002P-I\u0002P-I\n"
     ]
    }
   ],
   "source": [
    "# 下载并解压数据集\n",
    "from paddle.utils.download import get_path_from_url\n",
    "URL = \"https://paddlenlp.bj.bcebos.com/paddlenlp/datasets/waybill.tar.gz\"\n",
    "get_path_from_url(URL, \"./\")\n",
    "\n",
    "# 查看预测的数据\n",
    "!head -n 5 data/test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import paddle\n",
    "from paddlenlp.datasets import MapDataset\n",
    "from paddlenlp.data import Stack, Tuple, Pad\n",
    "from paddlenlp.transformers import ErnieTokenizer, ErnieForTokenClassification\n",
    "from paddlenlp.metrics import ChunkEvaluator\n",
    "from utils import convert_example, evaluate, predict, load_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载自定义数据集\n",
    "\n",
    "推荐使用MapDataset()自定义数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(datafiles):\n",
    "    def read(data_path):\n",
    "        with open(data_path, 'r', encoding='utf-8') as fp:\n",
    "            next(fp)  # Skip header\n",
    "            for line in fp.readlines():\n",
    "                words, labels = line.strip('\\n').split('\\t')\n",
    "                words = words.split('\\002')\n",
    "                labels = labels.split('\\002')\n",
    "                yield words, labels\n",
    "\n",
    "    if isinstance(datafiles, str):\n",
    "        return MapDataset(list(read(datafiles)))\n",
    "    elif isinstance(datafiles, list) or isinstance(datafiles, tuple):\n",
    "        return [MapDataset(list(read(datafile))) for datafile in datafiles]\n",
    "\n",
    "# Create dataset, tokenizer and dataloader.\n",
    "train_ds, dev_ds, test_ds = load_dataset(datafiles=(\n",
    "        './data/train.txt', './data/dev.txt', './data/test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['1', '6', '6', '2', '0', '2', '0', '0', '0', '7', '7', '宣', '荣', '嗣', '甘', '肃', '省', '白', '银', '市', '会', '宁', '县', '河', '畔', '镇', '十', '字', '街', '金', '海', '超', '市', '西', '行', '5', '0', '米'], ['T-B', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'P-B', 'P-I', 'P-I', 'A1-B', 'A1-I', 'A1-I', 'A2-B', 'A2-I', 'A2-I', 'A3-B', 'A3-I', 'A3-I', 'A4-B', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I'])\n",
      "(['1', '3', '5', '5', '2', '6', '6', '4', '3', '0', '7', '姜', '骏', '炜', '云', '南', '省', '德', '宏', '傣', '族', '景', '颇', '族', '自', '治', '州', '盈', '江', '县', '平', '原', '镇', '蜜', '回', '路', '下', '段'], ['T-B', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'P-B', 'P-I', 'P-I', 'A1-B', 'A1-I', 'A1-I', 'A2-B', 'A2-I', 'A2-I', 'A2-I', 'A2-I', 'A2-I', 'A2-I', 'A2-I', 'A2-I', 'A2-I', 'A3-B', 'A3-I', 'A3-I', 'A4-B', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I'])\n",
      "(['内', '蒙', '古', '自', '治', '区', '赤', '峰', '市', '阿', '鲁', '科', '尔', '沁', '旗', '汉', '林', '西', '街', '路', '南', '1', '3', '7', '0', '1', '0', '8', '5', '3', '9', '0', '那', '峥'], ['A1-B', 'A1-I', 'A1-I', 'A1-I', 'A1-I', 'A1-I', 'A2-B', 'A2-I', 'A2-I', 'A3-B', 'A3-I', 'A3-I', 'A3-I', 'A3-I', 'A3-I', 'A4-B', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'T-B', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'P-B', 'P-I'])\n",
      "(['广', '东', '省', '梅', '州', '市', '大', '埔', '县', '茶', '阳', '镇', '胜', '利', '路', '1', '3', '6', '0', '1', '3', '2', '8', '1', '7', '3', '张', '铱'], ['A1-B', 'A1-I', 'A1-I', 'A2-B', 'A2-I', 'A2-I', 'A3-B', 'A3-I', 'A3-I', 'A4-B', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'T-B', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'P-B', 'P-I'])\n",
      "(['新', '疆', '维', '吾', '尔', '自', '治', '区', '阿', '克', '苏', '地', '区', '阿', '克', '苏', '市', '步', '行', '街', '1', '0', '号', '1', '5', '8', '1', '0', '7', '8', '9', '3', '7', '8', '慕', '东', '霖'], ['A1-B', 'A1-I', 'A1-I', 'A1-I', 'A1-I', 'A1-I', 'A1-I', 'A1-I', 'A2-B', 'A2-I', 'A2-I', 'A2-I', 'A2-I', 'A3-B', 'A3-I', 'A3-I', 'A3-I', 'A4-B', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'A4-I', 'T-B', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'T-I', 'P-B', 'P-I', 'P-I'])\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(train_ds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每条数据包含一句文本和这个文本中每个汉字以及数字对应的label标签。\n",
    "\n",
    "之后，还需要对输入句子进行数据处理，如切词，映射词表id等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "\n",
    "预训练模型ERNIE对中文数据的处理是以字为单位。PaddleNLP对于各种预训练模型已经内置了相应的tokenizer。指定想要使用的模型名字即可加载对应的tokenizer。\n",
    "\n",
    "tokenizer作用为将原始输入文本转化成模型model可以接受的输入数据形式。\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://bj.bcebos.com/paddlehub/paddlehub-img/ernie_network_1.png\" hspace='10'/> <br />\n",
    "</p>\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://bj.bcebos.com/paddlehub/paddlehub-img/ernie_network_2.png\" hspace='10'/> <br />\n",
    "</p>\n",
    "<br><center>图3：ERNIE模型示意图</center></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-01-06 08:41:32,025] [    INFO]\u001b[0m - Already cached /root/.paddlenlp/models/ernie-1.0/vocab.txt\u001b[0m\n",
      "\u001b[32m[2023-01-06 08:41:32,036] [    INFO]\u001b[0m - tokenizer config file saved in /root/.paddlenlp/models/ernie-1.0/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2023-01-06 08:41:32,037] [    INFO]\u001b[0m - Special tokens file saved in /root/.paddlenlp/models/ernie-1.0/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 208, 515, 515, 249, 540, 249, 540, 540, 540, 589, 589, 803, 838, 2914, 1222, 1734, 244, 368, 797, 99, 32, 863, 308, 457, 2778, 484, 167, 436, 930, 192, 233, 634, 99, 213, 40, 317, 540, 256, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 40, [12, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 1, 1, 4, 5, 5, 6, 7, 7, 8, 9, 9, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12])\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "label_vocab = load_dict('./data/tag.dic')\n",
    "tokenizer = ErnieTokenizer.from_pretrained('ernie-1.0')\n",
    "\n",
    "trans_func = partial(convert_example, tokenizer=tokenizer, label_vocab=label_vocab)\n",
    "\n",
    "train_ds.map(trans_func)\n",
    "dev_ds.map(trans_func)\n",
    "test_ds.map(trans_func)\n",
    "print (train_ds[0])\n",
    "print (type(train_ds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读入\n",
    "\n",
    "使用`paddle.io.DataLoader`接口多线程异步加载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_label = -1\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input_ids\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # token_type_ids\n",
    "    Stack(),  # seq_len\n",
    "    Pad(axis=0, pad_val=ignore_label)  # labels\n",
    "): fn(samples)\n",
    "\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size=36,\n",
    "    return_list=True,\n",
    "    collate_fn=batchify_fn)\n",
    "dev_loader = paddle.io.DataLoader(\n",
    "    dataset=dev_ds,\n",
    "    batch_size=36,\n",
    "    return_list=True,\n",
    "    collate_fn=batchify_fn)\n",
    "test_loader = paddle.io.DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=36,\n",
    "    return_list=True,\n",
    "    collate_fn=batchify_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PaddleNLP一键加载预训练模型\n",
    "\n",
    "\n",
    "快递单信息抽取本质是一个序列标注任务，PaddleNLP对于各种预训练模型已经内置了对于下游任务文本分类Fine-tune网络。以下教程以ERNIE为预训练模型完成序列标注任务。\n",
    "\n",
    "`paddlenlp.transformers.ErnieForTokenClassification()`一行代码即可加载预训练模型ERNIE用于序列标注任务的fine-tune网络。其在ERNIE模型后拼接上一个全连接网络进行分类。\n",
    "\n",
    "`paddlenlp.transformers.ErnieForTokenClassification.from_pretrained()`方法只需指定想要使用的模型名称和文本分类的类别数即可完成定义模型网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-01-06 08:41:32,130] [    INFO]\u001b[0m - Model config ErnieConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"enable_recompute\": false,\n",
      "  \"fuse\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 2048,\n",
      "  \"model_type\": \"ernie\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"paddlenlp_version\": null,\n",
      "  \"pool_act\": \"tanh\",\n",
      "  \"task_id\": 0,\n",
      "  \"task_type_vocab_size\": 16,\n",
      "  \"type_vocab_size\": 4,\n",
      "  \"use_task_id\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\u001b[0m\n",
      "\u001b[32m[2023-01-06 08:41:32,132] [    INFO]\u001b[0m - Configuration saved in /root/.paddlenlp/models/ernie-3.0-medium-zh/config.json\u001b[0m\n",
      "W0106 08:41:32.136020 95744 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.7, Runtime API Version: 11.7\n",
      "W0106 08:41:32.143100 95744 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.\n",
      "\u001b[32m[2023-01-06 08:41:38,771] [    INFO]\u001b[0m - Downloading ernie_3.0_medium_zh.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams\u001b[0m\n",
      "100%|██████████| 313M/313M [00:04<00:00, 79.5MB/s] \n",
      "\u001b[33m[2023-01-06 08:41:44,045] [ WARNING]\u001b[0m - Some weights of the model checkpoint at ernie-3.0-medium-zh were not used when initializing ErnieForTokenClassification: ['ernie.encoder.layers.6.self_attn.k_proj.bias', 'ernie.encoder.layers.6.norm1.bias', 'ernie.encoder.layers.6.linear2.bias', 'ernie.encoder.layers.6.self_attn.out_proj.weight', 'ernie.encoder.layers.6.self_attn.q_proj.bias', 'ernie.encoder.layers.6.norm2.bias', 'ernie.encoder.layers.6.self_attn.q_proj.weight', 'ernie.encoder.layers.6.linear1.weight', 'ernie.encoder.layers.6.norm1.weight', 'ernie.encoder.layers.6.self_attn.k_proj.weight', 'ernie.encoder.layers.6.linear1.bias', 'ernie.encoder.layers.6.self_attn.v_proj.bias', 'ernie.encoder.layers.6.linear2.weight', 'ernie.encoder.layers.6.self_attn.out_proj.bias', 'ernie.encoder.layers.6.self_attn.v_proj.weight', 'ernie.encoder.layers.6.norm2.weight']\n",
      "- This IS expected if you are initializing ErnieForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[33m[2023-01-06 08:41:44,046] [ WARNING]\u001b[0m - Some weights of ErnieForTokenClassification were not initialized from the model checkpoint at ernie-3.0-medium-zh and are newly initialized: ['ernie.pooler.dense.bias', 'classifier.weight', 'classifier.bias', 'ernie.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define the model netword and its loss\n",
    "model = ErnieForTokenClassification.from_pretrained(\"ernie-3.0-medium-zh\", num_classes=len(label_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PaddleNLP不仅支持ERNIE预训练模型，还支持BERT、RoBERTa、Electra等预训练模型。\n",
    "下表汇总了目前PaddleNLP支持的各类预训练模型。您可以使用PaddleNLP提供的模型，完成文本分类、序列标注、问答等任务。同时我们提供了众多预训练模型的参数权重供用户使用，其中包含了二十多种中文语言模型的预训练权重。中文的预训练模型有`bert-base-chinese, bert-wwm-chinese, bert-wwm-ext-chinese, ernie-1.0, ernie-tiny, gpt2-base-cn, roberta-wwm-ext, roberta-wwm-ext-large, rbt3, rbtl3, chinese-electra-base, chinese-electra-small, chinese-xlnet-base, chinese-xlnet-mid, chinese-xlnet-large, unified_transformer-12L-cn, unified_transformer-12L-cn-luge`等。\n",
    "\n",
    "更多预训练模型参考：[PaddleNLP Transformer API](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/transformers.md)。\n",
    "\n",
    "更多预训练模型fine-tune下游任务使用方法，请参考：[examples](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置Fine-Tune优化策略，模型配置\n",
    "适用于ERNIE/BERT这类Transformer模型的迁移优化学习率策略为warmup的动态学习率。\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/2bc624280a614a80b5449773192be460f195b13af89e4e5cbaf62bf6ac16de2c\" width=\"40%\" height=\"30%\"/> <br />\n",
    "</p><br><center>图4：动态学习率示意图</center></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = ChunkEvaluator(label_list=label_vocab.keys(), suffix=True)\n",
    "loss_fn = paddle.nn.loss.CrossEntropyLoss(ignore_index=ignore_label)\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=2e-5, parameters=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练与评估\n",
    "\n",
    "\n",
    "模型训练的过程通常有以下步骤：\n",
    "\n",
    "1. 从dataloader中取出一个batch data\n",
    "2. 将batch data喂给model，做前向计算\n",
    "3. 将前向计算结果传给损失函数，计算loss。将前向计算结果传给评价方法，计算评价指标。\n",
    "4. loss反向回传，更新梯度。重复以上步骤。\n",
    "\n",
    "每训练一个epoch时，程序将会评估一次，评估当前模型训练的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 - step:1 - loss: 1.519485\n",
      "epoch:0 - step:2 - loss: 1.733694\n",
      "epoch:0 - step:3 - loss: 1.578577\n",
      "epoch:0 - step:4 - loss: 1.490346\n",
      "epoch:0 - step:5 - loss: 1.208969\n",
      "epoch:0 - step:6 - loss: 1.160242\n",
      "epoch:0 - step:7 - loss: 1.091293\n",
      "epoch:0 - step:8 - loss: 0.951492\n",
      "epoch:0 - step:9 - loss: 0.994918\n",
      "epoch:0 - step:10 - loss: 0.888747\n",
      "epoch:0 - step:11 - loss: 0.782466\n",
      "epoch:0 - step:12 - loss: 0.689489\n",
      "epoch:0 - step:13 - loss: 0.605482\n",
      "epoch:0 - step:14 - loss: 0.647149\n",
      "epoch:0 - step:15 - loss: 0.667218\n",
      "epoch:0 - step:16 - loss: 0.512948\n",
      "epoch:0 - step:17 - loss: 0.543177\n",
      "epoch:0 - step:18 - loss: 0.475133\n",
      "epoch:0 - step:19 - loss: 0.458999\n",
      "epoch:0 - step:20 - loss: 0.446542\n",
      "epoch:0 - step:21 - loss: 0.377728\n",
      "epoch:0 - step:22 - loss: 0.327557\n",
      "epoch:0 - step:23 - loss: 0.317280\n",
      "epoch:0 - step:24 - loss: 0.290944\n",
      "epoch:0 - step:25 - loss: 0.296275\n",
      "epoch:0 - step:26 - loss: 0.228879\n",
      "epoch:0 - step:27 - loss: 0.199604\n",
      "epoch:0 - step:28 - loss: 0.233621\n",
      "epoch:0 - step:29 - loss: 0.214362\n",
      "epoch:0 - step:30 - loss: 0.155938\n",
      "epoch:0 - step:31 - loss: 0.150222\n",
      "epoch:0 - step:32 - loss: 0.155987\n",
      "epoch:0 - step:33 - loss: 0.130316\n",
      "epoch:0 - step:34 - loss: 0.112106\n",
      "epoch:0 - step:35 - loss: 0.109375\n",
      "epoch:0 - step:36 - loss: 0.105234\n",
      "epoch:0 - step:37 - loss: 0.109266\n",
      "epoch:0 - step:38 - loss: 0.097402\n",
      "epoch:0 - step:39 - loss: 0.090114\n",
      "epoch:0 - step:40 - loss: 0.092640\n",
      "epoch:0 - step:41 - loss: 0.088076\n",
      "epoch:0 - step:42 - loss: 0.078362\n",
      "epoch:0 - step:43 - loss: 0.073687\n",
      "epoch:0 - step:44 - loss: 0.062487\n",
      "epoch:0 - step:45 - loss: 0.046418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2023-01-06 08:41:57,925] [ WARNING]\u001b[0m - Compatibility Warning: The params of ChunkEvaluator.compute has been modified. The old version is `inputs`, `lengths`, `predictions`, `labels` while the current version is `lengths`, `predictions`, `labels`.  Please update the usage.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval precision: 0.951480 - recall: 0.973087 - f1: 0.962162\n",
      "epoch:1 - step:46 - loss: 0.046304\n",
      "epoch:1 - step:47 - loss: 0.064895\n",
      "epoch:1 - step:48 - loss: 0.064102\n",
      "epoch:1 - step:49 - loss: 0.046157\n",
      "epoch:1 - step:50 - loss: 0.054858\n",
      "epoch:1 - step:51 - loss: 0.052414\n",
      "epoch:1 - step:52 - loss: 0.057763\n",
      "epoch:1 - step:53 - loss: 0.036757\n",
      "epoch:1 - step:54 - loss: 0.040201\n",
      "epoch:1 - step:55 - loss: 0.044538\n",
      "epoch:1 - step:56 - loss: 0.049160\n",
      "epoch:1 - step:57 - loss: 0.030971\n",
      "epoch:1 - step:58 - loss: 0.026684\n",
      "epoch:1 - step:59 - loss: 0.022707\n",
      "epoch:1 - step:60 - loss: 0.060200\n",
      "epoch:1 - step:61 - loss: 0.041511\n",
      "epoch:1 - step:62 - loss: 0.038473\n",
      "epoch:1 - step:63 - loss: 0.021925\n",
      "epoch:1 - step:64 - loss: 0.040109\n",
      "epoch:1 - step:65 - loss: 0.043085\n",
      "epoch:1 - step:66 - loss: 0.022607\n",
      "epoch:1 - step:67 - loss: 0.022245\n",
      "epoch:1 - step:68 - loss: 0.022844\n",
      "epoch:1 - step:69 - loss: 0.019684\n",
      "epoch:1 - step:70 - loss: 0.029012\n",
      "epoch:1 - step:71 - loss: 0.024516\n",
      "epoch:1 - step:72 - loss: 0.022336\n",
      "epoch:1 - step:73 - loss: 0.044095\n",
      "epoch:1 - step:74 - loss: 0.025623\n",
      "epoch:1 - step:75 - loss: 0.017132\n",
      "epoch:1 - step:76 - loss: 0.023843\n",
      "epoch:1 - step:77 - loss: 0.017463\n",
      "epoch:1 - step:78 - loss: 0.032788\n",
      "epoch:1 - step:79 - loss: 0.017408\n",
      "epoch:1 - step:80 - loss: 0.017860\n",
      "epoch:1 - step:81 - loss: 0.015269\n",
      "epoch:1 - step:82 - loss: 0.025397\n",
      "epoch:1 - step:83 - loss: 0.025394\n",
      "epoch:1 - step:84 - loss: 0.014182\n",
      "epoch:1 - step:85 - loss: 0.015697\n",
      "epoch:1 - step:86 - loss: 0.030368\n",
      "epoch:1 - step:87 - loss: 0.026871\n",
      "epoch:1 - step:88 - loss: 0.014154\n",
      "epoch:1 - step:89 - loss: 0.019668\n",
      "epoch:1 - step:90 - loss: 0.009234\n",
      "eval precision: 0.986577 - recall: 0.989066 - f1: 0.987820\n",
      "epoch:2 - step:91 - loss: 0.016342\n",
      "epoch:2 - step:92 - loss: 0.012547\n",
      "epoch:2 - step:93 - loss: 0.014820\n",
      "epoch:2 - step:94 - loss: 0.015785\n",
      "epoch:2 - step:95 - loss: 0.024186\n",
      "epoch:2 - step:96 - loss: 0.010440\n",
      "epoch:2 - step:97 - loss: 0.017595\n",
      "epoch:2 - step:98 - loss: 0.008290\n",
      "epoch:2 - step:99 - loss: 0.013068\n",
      "epoch:2 - step:100 - loss: 0.015602\n",
      "epoch:2 - step:101 - loss: 0.018131\n",
      "epoch:2 - step:102 - loss: 0.011656\n",
      "epoch:2 - step:103 - loss: 0.010506\n",
      "epoch:2 - step:104 - loss: 0.008387\n",
      "epoch:2 - step:105 - loss: 0.031132\n",
      "epoch:2 - step:106 - loss: 0.021003\n",
      "epoch:2 - step:107 - loss: 0.017165\n",
      "epoch:2 - step:108 - loss: 0.009256\n",
      "epoch:2 - step:109 - loss: 0.027563\n",
      "epoch:2 - step:110 - loss: 0.031132\n",
      "epoch:2 - step:111 - loss: 0.009451\n",
      "epoch:2 - step:112 - loss: 0.013269\n",
      "epoch:2 - step:113 - loss: 0.007502\n",
      "epoch:2 - step:114 - loss: 0.008782\n",
      "epoch:2 - step:115 - loss: 0.011810\n",
      "epoch:2 - step:116 - loss: 0.010892\n",
      "epoch:2 - step:117 - loss: 0.011242\n",
      "epoch:2 - step:118 - loss: 0.021327\n",
      "epoch:2 - step:119 - loss: 0.014445\n",
      "epoch:2 - step:120 - loss: 0.008356\n",
      "epoch:2 - step:121 - loss: 0.021661\n",
      "epoch:2 - step:122 - loss: 0.007472\n",
      "epoch:2 - step:123 - loss: 0.033742\n",
      "epoch:2 - step:124 - loss: 0.005809\n",
      "epoch:2 - step:125 - loss: 0.007874\n",
      "epoch:2 - step:126 - loss: 0.010861\n",
      "epoch:2 - step:127 - loss: 0.018419\n",
      "epoch:2 - step:128 - loss: 0.021645\n",
      "epoch:2 - step:129 - loss: 0.007075\n",
      "epoch:2 - step:130 - loss: 0.007709\n",
      "epoch:2 - step:131 - loss: 0.010611\n",
      "epoch:2 - step:132 - loss: 0.014675\n",
      "epoch:2 - step:133 - loss: 0.008122\n",
      "epoch:2 - step:134 - loss: 0.008830\n",
      "epoch:2 - step:135 - loss: 0.006544\n",
      "eval precision: 0.988255 - recall: 0.990749 - f1: 0.989500\n",
      "epoch:3 - step:136 - loss: 0.010543\n",
      "epoch:3 - step:137 - loss: 0.006744\n",
      "epoch:3 - step:138 - loss: 0.006794\n",
      "epoch:3 - step:139 - loss: 0.010664\n",
      "epoch:3 - step:140 - loss: 0.012682\n",
      "epoch:3 - step:141 - loss: 0.012078\n",
      "epoch:3 - step:142 - loss: 0.009664\n",
      "epoch:3 - step:143 - loss: 0.004259\n",
      "epoch:3 - step:144 - loss: 0.007661\n",
      "epoch:3 - step:145 - loss: 0.009047\n",
      "epoch:3 - step:146 - loss: 0.010193\n",
      "epoch:3 - step:147 - loss: 0.005608\n",
      "epoch:3 - step:148 - loss: 0.004444\n",
      "epoch:3 - step:149 - loss: 0.007945\n",
      "epoch:3 - step:150 - loss: 0.010500\n",
      "epoch:3 - step:151 - loss: 0.007399\n",
      "epoch:3 - step:152 - loss: 0.005984\n",
      "epoch:3 - step:153 - loss: 0.012924\n",
      "epoch:3 - step:154 - loss: 0.012300\n",
      "epoch:3 - step:155 - loss: 0.027567\n",
      "epoch:3 - step:156 - loss: 0.007301\n",
      "epoch:3 - step:157 - loss: 0.009142\n",
      "epoch:3 - step:158 - loss: 0.009376\n",
      "epoch:3 - step:159 - loss: 0.007095\n",
      "epoch:3 - step:160 - loss: 0.009184\n",
      "epoch:3 - step:161 - loss: 0.005269\n",
      "epoch:3 - step:162 - loss: 0.008374\n",
      "epoch:3 - step:163 - loss: 0.012111\n",
      "epoch:3 - step:164 - loss: 0.007357\n",
      "epoch:3 - step:165 - loss: 0.004702\n",
      "epoch:3 - step:166 - loss: 0.005121\n",
      "epoch:3 - step:167 - loss: 0.005263\n",
      "epoch:3 - step:168 - loss: 0.019791\n",
      "epoch:3 - step:169 - loss: 0.006078\n",
      "epoch:3 - step:170 - loss: 0.010084\n",
      "epoch:3 - step:171 - loss: 0.005366\n",
      "epoch:3 - step:172 - loss: 0.014294\n",
      "epoch:3 - step:173 - loss: 0.014549\n",
      "epoch:3 - step:174 - loss: 0.006107\n",
      "epoch:3 - step:175 - loss: 0.005071\n",
      "epoch:3 - step:176 - loss: 0.011149\n",
      "epoch:3 - step:177 - loss: 0.009264\n",
      "epoch:3 - step:178 - loss: 0.005252\n",
      "epoch:3 - step:179 - loss: 0.005852\n",
      "epoch:3 - step:180 - loss: 0.008716\n",
      "eval precision: 0.985786 - recall: 0.991590 - f1: 0.988679\n",
      "epoch:4 - step:181 - loss: 0.006627\n",
      "epoch:4 - step:182 - loss: 0.003209\n",
      "epoch:4 - step:183 - loss: 0.004778\n",
      "epoch:4 - step:184 - loss: 0.004795\n",
      "epoch:4 - step:185 - loss: 0.004432\n",
      "epoch:4 - step:186 - loss: 0.004188\n",
      "epoch:4 - step:187 - loss: 0.006681\n",
      "epoch:4 - step:188 - loss: 0.003296\n",
      "epoch:4 - step:189 - loss: 0.003796\n",
      "epoch:4 - step:190 - loss: 0.008727\n",
      "epoch:4 - step:191 - loss: 0.007715\n",
      "epoch:4 - step:192 - loss: 0.003304\n",
      "epoch:4 - step:193 - loss: 0.004035\n",
      "epoch:4 - step:194 - loss: 0.004137\n",
      "epoch:4 - step:195 - loss: 0.012662\n",
      "epoch:4 - step:196 - loss: 0.004819\n",
      "epoch:4 - step:197 - loss: 0.003667\n",
      "epoch:4 - step:198 - loss: 0.003302\n",
      "epoch:4 - step:199 - loss: 0.006479\n",
      "epoch:4 - step:200 - loss: 0.027380\n",
      "epoch:4 - step:201 - loss: 0.005841\n",
      "epoch:4 - step:202 - loss: 0.008021\n",
      "epoch:4 - step:203 - loss: 0.005744\n",
      "epoch:4 - step:204 - loss: 0.002646\n",
      "epoch:4 - step:205 - loss: 0.005619\n",
      "epoch:4 - step:206 - loss: 0.003574\n",
      "epoch:4 - step:207 - loss: 0.009143\n",
      "epoch:4 - step:208 - loss: 0.003800\n",
      "epoch:4 - step:209 - loss: 0.007778\n",
      "epoch:4 - step:210 - loss: 0.006406\n",
      "epoch:4 - step:211 - loss: 0.004621\n",
      "epoch:4 - step:212 - loss: 0.003718\n",
      "epoch:4 - step:213 - loss: 0.020140\n",
      "epoch:4 - step:214 - loss: 0.002224\n",
      "epoch:4 - step:215 - loss: 0.002332\n",
      "epoch:4 - step:216 - loss: 0.002543\n",
      "epoch:4 - step:217 - loss: 0.007605\n",
      "epoch:4 - step:218 - loss: 0.011341\n",
      "epoch:4 - step:219 - loss: 0.004264\n",
      "epoch:4 - step:220 - loss: 0.004284\n",
      "epoch:4 - step:221 - loss: 0.006032\n",
      "epoch:4 - step:222 - loss: 0.007599\n",
      "epoch:4 - step:223 - loss: 0.006985\n",
      "epoch:4 - step:224 - loss: 0.002863\n",
      "epoch:4 - step:225 - loss: 0.002738\n",
      "eval precision: 0.992437 - recall: 0.993272 - f1: 0.992854\n",
      "epoch:5 - step:226 - loss: 0.002334\n",
      "epoch:5 - step:227 - loss: 0.003145\n",
      "epoch:5 - step:228 - loss: 0.003526\n",
      "epoch:5 - step:229 - loss: 0.004210\n",
      "epoch:5 - step:230 - loss: 0.002947\n",
      "epoch:5 - step:231 - loss: 0.005277\n",
      "epoch:5 - step:232 - loss: 0.003530\n",
      "epoch:5 - step:233 - loss: 0.002366\n",
      "epoch:5 - step:234 - loss: 0.003535\n",
      "epoch:5 - step:235 - loss: 0.003992\n",
      "epoch:5 - step:236 - loss: 0.004835\n",
      "epoch:5 - step:237 - loss: 0.005086\n",
      "epoch:5 - step:238 - loss: 0.001848\n",
      "epoch:5 - step:239 - loss: 0.001789\n",
      "epoch:5 - step:240 - loss: 0.009050\n",
      "epoch:5 - step:241 - loss: 0.002722\n",
      "epoch:5 - step:242 - loss: 0.002087\n",
      "epoch:5 - step:243 - loss: 0.003319\n",
      "epoch:5 - step:244 - loss: 0.006379\n",
      "epoch:5 - step:245 - loss: 0.024343\n",
      "epoch:5 - step:246 - loss: 0.003328\n",
      "epoch:5 - step:247 - loss: 0.005151\n",
      "epoch:5 - step:248 - loss: 0.002002\n",
      "epoch:5 - step:249 - loss: 0.002710\n",
      "epoch:5 - step:250 - loss: 0.007837\n",
      "epoch:5 - step:251 - loss: 0.002756\n",
      "epoch:5 - step:252 - loss: 0.002209\n",
      "epoch:5 - step:253 - loss: 0.007492\n",
      "epoch:5 - step:254 - loss: 0.004474\n",
      "epoch:5 - step:255 - loss: 0.004878\n",
      "epoch:5 - step:256 - loss: 0.002295\n",
      "epoch:5 - step:257 - loss: 0.002854\n",
      "epoch:5 - step:258 - loss: 0.011871\n",
      "epoch:5 - step:259 - loss: 0.002517\n",
      "epoch:5 - step:260 - loss: 0.003651\n",
      "epoch:5 - step:261 - loss: 0.009782\n",
      "epoch:5 - step:262 - loss: 0.005857\n",
      "epoch:5 - step:263 - loss: 0.006988\n",
      "epoch:5 - step:264 - loss: 0.002050\n",
      "epoch:5 - step:265 - loss: 0.007124\n",
      "epoch:5 - step:266 - loss: 0.005295\n",
      "epoch:5 - step:267 - loss: 0.004797\n",
      "epoch:5 - step:268 - loss: 0.008296\n",
      "epoch:5 - step:269 - loss: 0.008551\n",
      "epoch:5 - step:270 - loss: 0.001592\n",
      "eval precision: 0.993283 - recall: 0.994954 - f1: 0.994118\n",
      "epoch:6 - step:271 - loss: 0.002975\n",
      "epoch:6 - step:272 - loss: 0.004580\n",
      "epoch:6 - step:273 - loss: 0.005879\n",
      "epoch:6 - step:274 - loss: 0.003744\n",
      "epoch:6 - step:275 - loss: 0.002911\n",
      "epoch:6 - step:276 - loss: 0.002805\n",
      "epoch:6 - step:277 - loss: 0.008045\n",
      "epoch:6 - step:278 - loss: 0.003810\n",
      "epoch:6 - step:279 - loss: 0.004254\n",
      "epoch:6 - step:280 - loss: 0.002530\n",
      "epoch:6 - step:281 - loss: 0.005444\n",
      "epoch:6 - step:282 - loss: 0.002453\n",
      "epoch:6 - step:283 - loss: 0.001649\n",
      "epoch:6 - step:284 - loss: 0.003092\n",
      "epoch:6 - step:285 - loss: 0.004935\n",
      "epoch:6 - step:286 - loss: 0.003652\n",
      "epoch:6 - step:287 - loss: 0.003376\n",
      "epoch:6 - step:288 - loss: 0.003778\n",
      "epoch:6 - step:289 - loss: 0.005357\n",
      "epoch:6 - step:290 - loss: 0.016842\n",
      "epoch:6 - step:291 - loss: 0.002244\n",
      "epoch:6 - step:292 - loss: 0.003344\n",
      "epoch:6 - step:293 - loss: 0.002802\n",
      "epoch:6 - step:294 - loss: 0.001720\n",
      "epoch:6 - step:295 - loss: 0.002854\n",
      "epoch:6 - step:296 - loss: 0.002522\n",
      "epoch:6 - step:297 - loss: 0.002175\n",
      "epoch:6 - step:298 - loss: 0.004181\n",
      "epoch:6 - step:299 - loss: 0.003625\n",
      "epoch:6 - step:300 - loss: 0.001975\n",
      "epoch:6 - step:301 - loss: 0.001903\n",
      "epoch:6 - step:302 - loss: 0.003075\n",
      "epoch:6 - step:303 - loss: 0.014546\n",
      "epoch:6 - step:304 - loss: 0.001362\n",
      "epoch:6 - step:305 - loss: 0.001730\n",
      "epoch:6 - step:306 - loss: 0.001893\n",
      "epoch:6 - step:307 - loss: 0.009092\n",
      "epoch:6 - step:308 - loss: 0.005232\n",
      "epoch:6 - step:309 - loss: 0.003080\n",
      "epoch:6 - step:310 - loss: 0.002111\n",
      "epoch:6 - step:311 - loss: 0.003864\n",
      "epoch:6 - step:312 - loss: 0.003097\n",
      "epoch:6 - step:313 - loss: 0.001542\n",
      "epoch:6 - step:314 - loss: 0.002793\n",
      "epoch:6 - step:315 - loss: 0.002096\n",
      "eval precision: 0.987448 - recall: 0.992431 - f1: 0.989933\n",
      "epoch:7 - step:316 - loss: 0.003178\n",
      "epoch:7 - step:317 - loss: 0.004078\n",
      "epoch:7 - step:318 - loss: 0.002129\n",
      "epoch:7 - step:319 - loss: 0.001923\n",
      "epoch:7 - step:320 - loss: 0.002484\n",
      "epoch:7 - step:321 - loss: 0.004673\n",
      "epoch:7 - step:322 - loss: 0.002754\n",
      "epoch:7 - step:323 - loss: 0.001728\n",
      "epoch:7 - step:324 - loss: 0.001546\n",
      "epoch:7 - step:325 - loss: 0.003901\n",
      "epoch:7 - step:326 - loss: 0.002350\n",
      "epoch:7 - step:327 - loss: 0.002856\n",
      "epoch:7 - step:328 - loss: 0.001068\n",
      "epoch:7 - step:329 - loss: 0.002810\n",
      "epoch:7 - step:330 - loss: 0.008882\n",
      "epoch:7 - step:331 - loss: 0.009348\n",
      "epoch:7 - step:332 - loss: 0.001550\n",
      "epoch:7 - step:333 - loss: 0.006728\n",
      "epoch:7 - step:334 - loss: 0.005484\n",
      "epoch:7 - step:335 - loss: 0.008595\n",
      "epoch:7 - step:336 - loss: 0.001652\n",
      "epoch:7 - step:337 - loss: 0.004858\n",
      "epoch:7 - step:338 - loss: 0.001563\n",
      "epoch:7 - step:339 - loss: 0.007303\n",
      "epoch:7 - step:340 - loss: 0.005718\n",
      "epoch:7 - step:341 - loss: 0.003534\n",
      "epoch:7 - step:342 - loss: 0.003537\n",
      "epoch:7 - step:343 - loss: 0.002740\n",
      "epoch:7 - step:344 - loss: 0.001807\n",
      "epoch:7 - step:345 - loss: 0.002762\n",
      "epoch:7 - step:346 - loss: 0.001161\n",
      "epoch:7 - step:347 - loss: 0.001467\n",
      "epoch:7 - step:348 - loss: 0.010777\n",
      "epoch:7 - step:349 - loss: 0.001249\n",
      "epoch:7 - step:350 - loss: 0.001113\n",
      "epoch:7 - step:351 - loss: 0.001826\n",
      "epoch:7 - step:352 - loss: 0.003145\n",
      "epoch:7 - step:353 - loss: 0.010587\n",
      "epoch:7 - step:354 - loss: 0.002010\n",
      "epoch:7 - step:355 - loss: 0.001716\n",
      "epoch:7 - step:356 - loss: 0.004476\n",
      "epoch:7 - step:357 - loss: 0.003313\n",
      "epoch:7 - step:358 - loss: 0.001207\n",
      "epoch:7 - step:359 - loss: 0.001566\n",
      "epoch:7 - step:360 - loss: 0.001651\n",
      "eval precision: 0.988265 - recall: 0.991590 - f1: 0.989924\n",
      "epoch:8 - step:361 - loss: 0.004309\n",
      "epoch:8 - step:362 - loss: 0.001596\n",
      "epoch:8 - step:363 - loss: 0.002308\n",
      "epoch:8 - step:364 - loss: 0.002242\n",
      "epoch:8 - step:365 - loss: 0.002161\n",
      "epoch:8 - step:366 - loss: 0.001321\n",
      "epoch:8 - step:367 - loss: 0.002348\n",
      "epoch:8 - step:368 - loss: 0.001050\n",
      "epoch:8 - step:369 - loss: 0.001439\n",
      "epoch:8 - step:370 - loss: 0.001425\n",
      "epoch:8 - step:371 - loss: 0.002192\n",
      "epoch:8 - step:372 - loss: 0.001802\n",
      "epoch:8 - step:373 - loss: 0.000890\n",
      "epoch:8 - step:374 - loss: 0.001095\n",
      "epoch:8 - step:375 - loss: 0.002075\n",
      "epoch:8 - step:376 - loss: 0.002032\n",
      "epoch:8 - step:377 - loss: 0.002494\n",
      "epoch:8 - step:378 - loss: 0.001618\n",
      "epoch:8 - step:379 - loss: 0.001275\n",
      "epoch:8 - step:380 - loss: 0.002204\n",
      "epoch:8 - step:381 - loss: 0.001729\n",
      "epoch:8 - step:382 - loss: 0.002508\n",
      "epoch:8 - step:383 - loss: 0.004590\n",
      "epoch:8 - step:384 - loss: 0.000968\n",
      "epoch:8 - step:385 - loss: 0.001761\n",
      "epoch:8 - step:386 - loss: 0.003419\n",
      "epoch:8 - step:387 - loss: 0.002121\n",
      "epoch:8 - step:388 - loss: 0.002010\n",
      "epoch:8 - step:389 - loss: 0.001226\n",
      "epoch:8 - step:390 - loss: 0.002318\n",
      "epoch:8 - step:391 - loss: 0.001440\n",
      "epoch:8 - step:392 - loss: 0.006591\n",
      "epoch:8 - step:393 - loss: 0.004379\n",
      "epoch:8 - step:394 - loss: 0.001284\n",
      "epoch:8 - step:395 - loss: 0.000854\n",
      "epoch:8 - step:396 - loss: 0.001013\n",
      "epoch:8 - step:397 - loss: 0.002025\n",
      "epoch:8 - step:398 - loss: 0.007420\n",
      "epoch:8 - step:399 - loss: 0.001982\n",
      "epoch:8 - step:400 - loss: 0.001297\n",
      "epoch:8 - step:401 - loss: 0.001941\n",
      "epoch:8 - step:402 - loss: 0.001140\n",
      "epoch:8 - step:403 - loss: 0.001060\n",
      "epoch:8 - step:404 - loss: 0.003773\n",
      "epoch:8 - step:405 - loss: 0.006434\n",
      "eval precision: 0.994958 - recall: 0.995795 - f1: 0.995376\n",
      "epoch:9 - step:406 - loss: 0.001088\n",
      "epoch:9 - step:407 - loss: 0.008275\n",
      "epoch:9 - step:408 - loss: 0.003262\n",
      "epoch:9 - step:409 - loss: 0.001344\n",
      "epoch:9 - step:410 - loss: 0.001119\n",
      "epoch:9 - step:411 - loss: 0.001608\n",
      "epoch:9 - step:412 - loss: 0.005499\n",
      "epoch:9 - step:413 - loss: 0.002500\n",
      "epoch:9 - step:414 - loss: 0.003032\n",
      "epoch:9 - step:415 - loss: 0.002901\n",
      "epoch:9 - step:416 - loss: 0.005657\n",
      "epoch:9 - step:417 - loss: 0.002925\n",
      "epoch:9 - step:418 - loss: 0.001180\n",
      "epoch:9 - step:419 - loss: 0.001156\n",
      "epoch:9 - step:420 - loss: 0.002727\n",
      "epoch:9 - step:421 - loss: 0.004712\n",
      "epoch:9 - step:422 - loss: 0.001600\n",
      "epoch:9 - step:423 - loss: 0.000880\n",
      "epoch:9 - step:424 - loss: 0.001243\n",
      "epoch:9 - step:425 - loss: 0.002234\n",
      "epoch:9 - step:426 - loss: 0.001525\n",
      "epoch:9 - step:427 - loss: 0.003692\n",
      "epoch:9 - step:428 - loss: 0.001012\n",
      "epoch:9 - step:429 - loss: 0.001215\n",
      "epoch:9 - step:430 - loss: 0.003387\n",
      "epoch:9 - step:431 - loss: 0.001799\n",
      "epoch:9 - step:432 - loss: 0.001089\n",
      "epoch:9 - step:433 - loss: 0.001929\n",
      "epoch:9 - step:434 - loss: 0.001606\n",
      "epoch:9 - step:435 - loss: 0.000751\n",
      "epoch:9 - step:436 - loss: 0.001145\n",
      "epoch:9 - step:437 - loss: 0.000957\n",
      "epoch:9 - step:438 - loss: 0.000996\n",
      "epoch:9 - step:439 - loss: 0.001637\n",
      "epoch:9 - step:440 - loss: 0.000841\n",
      "epoch:9 - step:441 - loss: 0.000877\n",
      "epoch:9 - step:442 - loss: 0.002438\n",
      "epoch:9 - step:443 - loss: 0.005434\n",
      "epoch:9 - step:444 - loss: 0.001273\n",
      "epoch:9 - step:445 - loss: 0.001209\n",
      "epoch:9 - step:446 - loss: 0.000898\n",
      "epoch:9 - step:447 - loss: 0.001687\n",
      "epoch:9 - step:448 - loss: 0.000916\n",
      "epoch:9 - step:449 - loss: 0.000957\n",
      "epoch:9 - step:450 - loss: 0.001711\n",
      "eval precision: 0.992437 - recall: 0.993272 - f1: 0.992854\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for epoch in range(10):\n",
    "    for idx, (input_ids, token_type_ids, length, labels) in enumerate(train_loader):\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = paddle.mean(loss_fn(logits, labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        step += 1\n",
    "        print(\"epoch:%d - step:%d - loss: %f\" % (epoch, step, loss))\n",
    "    evaluate(model, metric, dev_loader)\n",
    "\n",
    "    paddle.save(model.state_dict(),\n",
    "                './ernie_result/model_%d.pdparams' % step)\n",
    "# model.save_pretrained('./checkpoint')\n",
    "# tokenizer.save_pretrained('./checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测\n",
    "\n",
    "训练保存好的模型，即可用于预测。如以下示例代码自定义预测数据，调用`predict()`函数即可一键预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results have been saved in the file: ernie_results.txt, some examples are shown below: \n",
      "('黑龙江省', 'A1')('双鸭山市', 'A2')('尖山区', 'A3')('八马路与东平行路交叉口北40米', 'A4')('韦业涛', 'P')('18600009172', 'T')\n",
      "('广西壮族自治区', 'A1')('桂林市', 'A2')('雁山区', 'A3')('雁山镇西龙村老年活动中心', 'A4')('17610348888', 'T')('羊卓卫', 'P')\n",
      "('15652864561', 'T')('河南省', 'A1')('开封市', 'A2')('顺河回族区', 'A3')('顺河区公园路32号', 'A4')('赵本山', 'P')\n",
      "('河北省', 'A1')('唐山市', 'A2')('玉田县', 'A3')('无终大街159号', 'A4')('18614253058', 'T')('尚汉生', 'P')\n",
      "('台湾', 'A1')('台中市', 'A2')('北区', 'A3')('北区锦新街18号', 'A4')('18511226708', 'T')('蓟丽', 'P')\n",
      "('廖梓琪', 'P')('18514743222', 'T')('湖北省', 'A1')('宜昌市', 'A2')('长阳土家族自治县', 'A3')('贺家坪镇贺家坪村一组临河1号', 'A4')\n",
      "('江苏省', 'A1')('南通市', 'A2')('海门市', 'A3')('孝威村孝威路88号', 'A4')('18611840623', 'T')('计星仪', 'P')\n",
      "('17601674746', 'T')('赵春丽', 'P')('内蒙古自治区', 'A1')('乌兰察布市', 'A2')('凉城县', 'A3')('新建街', 'A4')\n",
      "('云南省', 'A1')('临沧市', 'A2')('耿马傣族佤族自治县', 'A3')('鑫源路法院对面', 'A4')('许贞爱', 'P')('18510566685', 'T')\n",
      "('四川省', 'A1')('成都市', 'A2')('双流区', 'A3')('东升镇北仓路196号', 'A4')('耿丕岭', 'P')('18513466161', 'T')\n"
     ]
    }
   ],
   "source": [
    "preds = predict(model, test_loader, test_ds, label_vocab)\n",
    "file_path = \"ernie_results.txt\"\n",
    "with open(file_path, \"w\", encoding=\"utf8\") as fout:\n",
    "    fout.write(\"\\n\".join(preds))\n",
    "# Print some examples\n",
    "print(\n",
    "    \"The results have been saved in the file: %s, some examples are shown below: \"\n",
    "    % file_path)\n",
    "print(\"\\n\".join(preds[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95744/1385736118.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mt_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mt_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't1' is not defined"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "\n",
    "paddle.enable_static()\n",
    "main_program = paddle.static.Program()\n",
    "startup_program = paddle.static.Program()\n",
    "\n",
    "with paddle.static.program_guard(main_program, startup_program):\n",
    "    t_1 = paddle.to_tensor([1,2,3])\n",
    "    t_2 = paddle.to_tensor([1,2,3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
