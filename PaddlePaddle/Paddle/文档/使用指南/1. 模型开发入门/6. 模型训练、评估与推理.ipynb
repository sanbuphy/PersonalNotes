{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grep: warning: GREP_OPTIONS is deprecated; please use an alias or script\n",
      "W0104 08:38:05.278307 47325 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.7, Runtime API Version: 11.6\n",
      "W0104 08:38:05.284775 47325 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.\n"
     ]
    }
   ],
   "source": [
    "# 模型训练、评估与推理\n",
    "'''\n",
    "飞桨框架提供了两种训练、评估与推理的方法：\n",
    "\n",
    "使用飞桨高层 API：先用 paddle.Model 对模型进行封装，然后通过 Model.fit 、 Model.evaluate 、 Model.predict 等完成模型的训练、评估与推理。该方式代码量少，适合快速上手。\n",
    "\n",
    "使用飞桨基础 API：提供了损失函数、优化器、评价指标、更新参数、反向传播等基础组件的实现，可以更灵活地应用到模型训练、评估与推理任务中，当然也可以很方便地自定义一些组件用于相关任务中。\n",
    "'''\n",
    "\n",
    "# 一、训练前准备\n",
    "## 1.1 （可选）指定训练的硬件\n",
    "\n",
    "## 1.2 准备训练用的数据集和模型\n",
    "import paddle\n",
    "from paddle.vision.transforms import Normalize\n",
    "\n",
    "transform = Normalize(mean=[127.5], std=[127.5], data_format='CHW')\n",
    "# 加载 MNIST 训练集和测试集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "\n",
    "# 模型组网，构建并初始化一个模型 mnist\n",
    "mnist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(1, -1), \n",
    "    paddle.nn.Linear(784, 512), \n",
    "    paddle.nn.ReLU(), \n",
    "    paddle.nn.Dropout(0.2), \n",
    "    paddle.nn.Linear(512, 10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step 938/938 [==============================] - loss: 0.2209 - acc: 0.9032 - 10ms/step          \n",
      "Epoch 2/5\n",
      "step 938/938 [==============================] - loss: 0.0476 - acc: 0.9492 - 7ms/step          \n",
      "Epoch 3/5\n",
      "step 938/938 [==============================] - loss: 0.1464 - acc: 0.9595 - 7ms/step          \n",
      "Epoch 4/5\n",
      "step 938/938 [==============================] - loss: 0.0127 - acc: 0.9661 - 7ms/step          \n",
      "Epoch 5/5\n",
      "step 938/938 [==============================] - loss: 0.1213 - acc: 0.9678 - 7ms/step          \n"
     ]
    }
   ],
   "source": [
    "# 二、使用 paddle.Model 高层 API 训练、评估与推理\n",
    "## 2.1 使用 paddle.Model 封装模型\n",
    "# 封装模型为一个 model 实例，便于进行后续的训练、评估和推理\n",
    "model = paddle.Model(mnist)\n",
    "\n",
    "\n",
    "## 2.2 使用 Model.prepare 配置训练准备参数\n",
    "# 为模型训练做准备，设置优化器及其学习率，并将网络的参数传入优化器，设置损失函数和精度计算方式\n",
    "model.prepare(optimizer=paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()), \n",
    "              loss=paddle.nn.CrossEntropyLoss(), \n",
    "              metrics=paddle.metric.Accuracy())\n",
    "\n",
    "## 2.3 使用 Model.fit 训练模型\n",
    "'''\n",
    "训练过程采用二层循环嵌套方式：内层循环完成整个数据集的一次遍历，采用分批次方式；\n",
    "外层循环根据设置的训练轮次完成数据集的多次遍历。因此需要指定至少三个关键参数：训练数据集，训练轮次和每批次大小:\n",
    "'''\n",
    "# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\n",
    "model.fit(train_dataset, \n",
    "          epochs=5, \n",
    "          batch_size=64,\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 10000/10000 [==============================] - loss: 2.5272e-05 - acc: 0.9702 - 7ms/step          \n",
      "Eval samples: 10000\n",
      "{'loss': [2.527205e-05], 'acc': 0.9702}\n"
     ]
    }
   ],
   "source": [
    "## 2.4 使用 Model.evaluate 评估模型\n",
    "# 用 evaluate 在测试集上对模型进行验证\n",
    "eval_result = model.evaluate(test_dataset, verbose=1)\n",
    "print(eval_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 10000/10000 [==============================] - 839us/step          \n",
      "Predict samples: 10000\n",
      "1\n",
      "[[ -3.0381637  -3.6759975   3.2124631   3.446025   -9.387213   -1.3628352\n",
      "  -14.971385   13.714459   -3.8737411  -0.0832907]]\n",
      "true label: [7], pred label: 7\n",
      "[[[-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -0.34117648  0.4509804   0.24705882  0.18431373\n",
      "   -0.5294118  -0.7176471  -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.          0.7411765   0.99215686  0.99215686  0.99215686\n",
      "    0.99215686  0.8901961   0.5529412   0.5529412   0.5529412\n",
      "    0.5529412   0.5529412   0.5529412   0.5529412   0.5529412\n",
      "    0.33333334 -0.5921569  -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -0.4745098  -0.10588235 -0.43529412 -0.10588235\n",
      "    0.2784314   0.78039217  0.99215686  0.7647059   0.99215686\n",
      "    0.99215686  0.99215686  0.9607843   0.79607844  0.99215686\n",
      "    0.99215686  0.09803922 -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -0.8666667  -0.48235294 -0.8901961  -0.4745098\n",
      "   -0.4745098  -0.4745098  -0.5372549  -0.8352941   0.8509804\n",
      "    0.99215686 -0.16862746 -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -0.34901962  0.9843137\n",
      "    0.6392157  -0.85882354 -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -0.827451    0.827451    1.\n",
      "   -0.34901962 -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.          0.01176471  0.99215686  0.8666667\n",
      "   -0.654902   -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -0.5372549   0.9529412   0.99215686 -0.5137255\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.          0.04313726  0.99215686  0.46666667 -0.9607843\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -0.92941177  0.60784316  0.94509804 -0.54509807 -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -0.01176471  0.99215686  0.42745098 -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -0.4117647\n",
      "    0.96862745  0.88235295 -0.5529412  -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -0.8509804   0.73333335\n",
      "    0.99215686  0.3019608  -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -0.9764706   0.5921569   0.99215686\n",
      "    0.7176471  -0.7254902  -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -0.7019608   0.99215686  0.99215686\n",
      "   -0.39607844 -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -0.75686276  0.75686276  0.99215686 -0.09803922\n",
      "   -0.99215686 -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.          0.04313726  0.99215686  0.99215686 -0.5921569\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -0.52156866  0.8980392   0.99215686  0.99215686 -0.5921569\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -0.05098039  0.99215686  0.99215686  0.7176471  -0.6862745\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -0.05098039  0.99215686  0.62352943 -0.85882354 -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.         -1.         -1.\n",
      "   -1.         -1.         -1.        ]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f82da9e9210>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 2.5 使用 Model.predict 执行推理\n",
    "\n",
    "# 用 predict 在测试集上对模型进行推理\n",
    "test_result = model.predict(test_dataset)\n",
    "# 由于模型是单一输出，test_result的形状为[1, 10000]，10000是测试数据集的数据量。这里打印第一个数据的结果，这个数组表示每个数字的预测概率\n",
    "print(len(test_result))\n",
    "print(test_result[0][0])\n",
    "\n",
    "'''\n",
    "模型是单一输出：[(numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n)]\n",
    "其中每个 numpy_ndarray_n 是对应原始数据经过模型计算后得到的预测结果，类型为 numpy 数组\n",
    "'''\n",
    "\n",
    "# 从测试集中取出一张图片\n",
    "img, label = test_dataset[0]\n",
    "\n",
    "# 打印推理结果，这里的argmax函数用于取出预测值中概率最高的一个的下标，作为预测标签\n",
    "pred_label = test_result[0][0].argmax()\n",
    "print('true label: {}, pred label: {}'.format(label, pred_label))\n",
    "# 使用matplotlib库，可视化图片\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img[0]) # 二维作图，取其中一个通道\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 900, loss is: [0.09216936], acc is: [0.953125]\n",
      "epoch: 1, batch_id: 900, loss is: [0.14373042], acc is: [0.96875]\n",
      "epoch: 2, batch_id: 900, loss is: [0.13587375], acc is: [0.96875]\n",
      "epoch: 3, batch_id: 900, loss is: [0.01337348], acc is: [1.]\n",
      "epoch: 4, batch_id: 900, loss is: [0.16672754], acc is: [0.9375]\n"
     ]
    }
   ],
   "source": [
    "# 三、使用基础 API 训练、评估与推理\n",
    "## 3.1 模型训练（拆解 Model.prepare、Model.fit）\n",
    "'''\n",
    "飞桨框架通过基础 API 对模型进行训练，对应高层 API 的 Model.prepare 与 Model.fit ，一般包括如下几个步骤：\n",
    "\n",
    "加载训练数据集、声明模型、设置模型实例为 train 模式\n",
    "\n",
    "设置优化器、损失函数与各个超参数\n",
    "\n",
    "设置模型训练的二层循环嵌套，并在内层循环嵌套中设置如下内容\n",
    "\n",
    "3.1 从数据读取器 DataLoader 获取一批次训练数据\n",
    "\n",
    "3.2 执行一次预测，即经过模型计算获得输入数据的预测值\n",
    "\n",
    "3.3 计算预测值与数据集标签的损失\n",
    "\n",
    "3.4 计算预测值与数据集标签的准确率\n",
    "\n",
    "3.5 将损失进行反向传播\n",
    "\n",
    "3.6 打印模型的轮数、批次、损失值、准确率等信息\n",
    "\n",
    "3.7 执行一次优化器步骤，即按照选择的优化算法，根据当前批次数据的梯度更新传入优化器的参数\n",
    "\n",
    "3.8 将优化器的梯度进行清零\n",
    "'''\n",
    "# dataset与mnist的定义与使用高层API的内容一致\n",
    "# 用 DataLoader 实现数据加载\n",
    "train_loader = paddle.io.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 将mnist模型及其所有子层设置为训练模式。这只会影响某些模块，如 Dropout 和 BatchNorm。\n",
    "mnist.train()\n",
    "\n",
    "# 设置迭代次数\n",
    "epochs = 5\n",
    "\n",
    "# 设置优化器\n",
    "optim = paddle.optimizer.Adam(parameters=mnist.parameters())\n",
    "# 设置损失函数\n",
    "loss_fn = paddle.nn.CrossEntropyLoss()\n",
    "for epoch in range(epochs):\n",
    "    for batch_id, data in enumerate(train_loader()):\n",
    "        \n",
    "        x_data = data[0]            # 训练数据\n",
    "        y_data = data[1]            # 训练数据标签\n",
    "        predicts = mnist(x_data)    # 预测结果  \n",
    "        \n",
    "        # 计算损失 等价于 prepare 中loss的设置\n",
    "        loss = loss_fn(predicts, y_data)\n",
    "        \n",
    "        # 计算准确率 等价于 prepare 中metrics的设置\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\n",
    "        \n",
    "        # 下面的反向传播、打印训练信息、更新参数、梯度清零都被封装到 Model.fit() 中\n",
    "        # 反向传播 \n",
    "        loss.backward()\n",
    "        \n",
    "        if (batch_id+1) % 900 == 0:\n",
    "            print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id+1, loss.numpy(), acc.numpy()))\n",
    "        # 更新参数 \n",
    "        optim.step()\n",
    "        # 梯度清零\n",
    "        optim.clear_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id: 30, loss is: [0.11612443], acc is: [0.953125]\n",
      "batch_id: 60, loss is: [0.16203663], acc is: [0.9375]\n",
      "batch_id: 90, loss is: [0.09520508], acc is: [0.984375]\n",
      "batch_id: 120, loss is: [0.00276513], acc is: [1.]\n",
      "batch_id: 150, loss is: [0.03584248], acc is: [0.984375]\n"
     ]
    }
   ],
   "source": [
    "## 3.2 模型评估（拆解 Model.evaluate）\n",
    "'''\n",
    "加载的数据从训练数据集改为测试数据集\n",
    "\n",
    "模型实例从 train 模式改为 eval 模式\n",
    "\n",
    "不需要反向传播、优化器参数更新和优化器梯度清零\n",
    "'''\n",
    "# 加载测试数据集\n",
    "test_loader = paddle.io.DataLoader(test_dataset, batch_size=64, drop_last=True)\n",
    "# 设置损失函数\n",
    "loss_fn = paddle.nn.CrossEntropyLoss()\n",
    "# 将该模型及其所有子层设置为预测模式。这只会影响某些模块，如Dropout和BatchNorm\n",
    "mnist.eval()\n",
    "# 禁用动态图梯度计算\n",
    "for batch_id, data in enumerate(test_loader()):\n",
    "    \n",
    "    x_data = data[0]            # 测试数据\n",
    "    y_data = data[1]            # 测试数据标签\n",
    "    predicts = mnist(x_data)    # 预测结果\n",
    "    \n",
    "    # 计算损失与精度\n",
    "    loss = loss_fn(predicts, y_data)\n",
    "    acc = paddle.metric.accuracy(predicts, y_data)\n",
    "    \n",
    "    # 打印信息\n",
    "    if (batch_id+1) % 30 == 0:\n",
    "        print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id+1, loss.numpy(), acc.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict finished\n",
      "true label: [7], pred label: [7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f82a63fdf50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 3.3 模型推理（拆解 Model.predict）\n",
    "'''\n",
    "加载待执行推理的测试数据，并将模型设置为 eval 模式\n",
    "\n",
    "读取测试数据并获得预测结果\n",
    "\n",
    "对预测结果进行后处理\n",
    "'''\n",
    "# 加载测试数据集\n",
    "test_loader = paddle.io.DataLoader(test_dataset, batch_size=64, drop_last=True)\n",
    "# 将该模型及其所有子层设置为预测模式\n",
    "mnist.eval()\n",
    "for batch_id, data in enumerate(test_loader()):\n",
    "    # 取出测试数据\n",
    "    x_data = data[0] \n",
    "    # 获取预测结果\n",
    "    predicts = mnist(x_data)\n",
    "print(\"predict finished\")\n",
    "\n",
    "# 从测试集中取出一组数据(一个batch)\n",
    "img, label = next(test_loader())\n",
    "\n",
    "# 执行推理并打印结果\n",
    "pred_label = mnist(img)[0].argmax()\n",
    "print('true label: {}, pred label: {}'.format(label[0].numpy(), pred_label[0].numpy()))\n",
    "# 可视化图片\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img[0][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
